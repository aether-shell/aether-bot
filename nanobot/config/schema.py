"""Configuration schema using Pydantic."""

from pathlib import Path
from pydantic import BaseModel, Field
from pydantic_settings import BaseSettings


class WhatsAppConfig(BaseModel):
    """WhatsApp channel configuration."""
    enabled: bool = False
    bridge_url: str = "ws://localhost:3001"
    allow_from: list[str] = Field(default_factory=list)  # Allowed phone numbers


class TelegramConfig(BaseModel):
    """Telegram channel configuration."""
    enabled: bool = False
    token: str = ""  # Bot token from @BotFather
    allow_from: list[str] = Field(default_factory=list)  # Allowed user IDs or usernames
    proxy: str | None = None  # HTTP/SOCKS5 proxy URL, e.g. "http://127.0.0.1:7890" or "socks5://127.0.0.1:1080"


class FeishuConfig(BaseModel):
    """Feishu/Lark channel configuration using WebSocket long connection."""
    enabled: bool = False
    app_id: str = ""  # App ID from Feishu Open Platform
    app_secret: str = ""  # App Secret from Feishu Open Platform
    encrypt_key: str = ""  # Encrypt Key for event subscription (optional)
    verification_token: str = ""  # Verification Token for event subscription (optional)
    allow_from: list[str] = Field(default_factory=list)  # Allowed user open_ids
    auto_react: bool = False  # Add reaction emoji on incoming messages
    show_context: bool = False  # Append context status to outbound messages


class ChannelsConfig(BaseModel):
    """Configuration for chat channels."""
    whatsapp: WhatsAppConfig = Field(default_factory=WhatsAppConfig)
    telegram: TelegramConfig = Field(default_factory=TelegramConfig)
    feishu: FeishuConfig = Field(default_factory=FeishuConfig)


class ContextConfig(BaseModel):
    """Conversation context configuration."""
    window_tokens: int = 32000
    reserve_tokens: int = 1024
    summarize_threshold: float = 0.75
    hard_limit_threshold: float = 0.9
    recent_messages: int = 20
    min_recent_messages: int = 6
    summary_max_tokens: int = 1200
    summary_model: str | None = None
    enable_native_session: bool = True


class AgentDefaults(BaseModel):
    """Default agent configuration."""
    workspace: str = "~/.nanobot/workspace"
    model: str = "anthropic/claude-opus-4-5"
    max_tokens: int = 8192
    temperature: float = 0.7
    max_tool_iterations: int = 20
    stream: bool = False
    stream_min_chars: int = 120
    stream_min_interval_s: float = 0.5
    context: ContextConfig = Field(default_factory=ContextConfig)


class AgentsConfig(BaseModel):
    """Agent configuration."""
    defaults: AgentDefaults = Field(default_factory=AgentDefaults)


class ProviderConfig(BaseModel):
    """LLM provider configuration."""
    api_key: str = ""
    api_base: str | None = None
    api_type: str | None = None  # e.g. "openai-responses" for /v1/responses
    headers: dict[str, str] | None = None  # Extra headers for provider requests
    proxy: str | None = None  # Optional proxy URL, e.g. "http://127.0.0.1:7897"
    drop_params: bool = False  # Drop optional params for strict gateways


class ProvidersConfig(BaseModel):
    """Configuration for LLM providers."""
    anthropic: ProviderConfig = Field(default_factory=ProviderConfig)
    openai: ProviderConfig = Field(default_factory=ProviderConfig)
    openrouter: ProviderConfig = Field(default_factory=ProviderConfig)
    deepseek: ProviderConfig = Field(default_factory=ProviderConfig)
    groq: ProviderConfig = Field(default_factory=ProviderConfig)
    zhipu: ProviderConfig = Field(default_factory=ProviderConfig)
    vllm: ProviderConfig = Field(default_factory=ProviderConfig)
    gemini: ProviderConfig = Field(default_factory=ProviderConfig)


class GatewayConfig(BaseModel):
    """Gateway/server configuration."""
    host: str = "0.0.0.0"
    port: int = 18790


class WebSearchConfig(BaseModel):
    """Web search tool configuration."""
    api_key: str = ""  # Brave Search API key
    max_results: int = 5


class WebToolsConfig(BaseModel):
    """Web tools configuration."""
    search: WebSearchConfig = Field(default_factory=WebSearchConfig)


class ExecToolConfig(BaseModel):
    """Shell exec tool configuration."""
    timeout: int = 60
    restrict_to_workspace: bool = False  # If true, block commands accessing paths outside workspace


class ToolsConfig(BaseModel):
    """Tools configuration."""
    web: WebToolsConfig = Field(default_factory=WebToolsConfig)
    exec: ExecToolConfig = Field(default_factory=ExecToolConfig)


class Config(BaseSettings):
    """Root configuration for nanobot."""
    agents: AgentsConfig = Field(default_factory=AgentsConfig)
    channels: ChannelsConfig = Field(default_factory=ChannelsConfig)
    providers: ProvidersConfig = Field(default_factory=ProvidersConfig)
    gateway: GatewayConfig = Field(default_factory=GatewayConfig)
    tools: ToolsConfig = Field(default_factory=ToolsConfig)
    
    @property
    def workspace_path(self) -> Path:
        """Get expanded workspace path."""
        return Path(self.agents.defaults.workspace).expanduser()
    
    def get_api_key(self) -> str | None:
        """Get API key in priority order: OpenRouter > DeepSeek > Anthropic > OpenAI > Gemini > Zhipu > Groq > vLLM."""
        return (
            self.providers.openrouter.api_key or
            self.providers.deepseek.api_key or
            self.providers.anthropic.api_key or
            self.providers.openai.api_key or
            self.providers.gemini.api_key or
            self.providers.zhipu.api_key or
            self.providers.groq.api_key or
            self.providers.vllm.api_key or
            None
        )
    
    def get_api_base(self) -> str | None:
        """Get API base URL if using OpenRouter, Zhipu or vLLM."""
        if self.providers.openrouter.api_key:
            return self.providers.openrouter.api_base or "https://openrouter.ai/api/v1"
        if self.providers.openai.api_key and self.providers.openai.api_base:
            return self.providers.openai.api_base
        if self.providers.zhipu.api_key:
            return self.providers.zhipu.api_base
        if self.providers.vllm.api_base:
            return self.providers.vllm.api_base
        return None

    def get_api_type(self) -> str | None:
        """Get API type for the active provider (e.g. openai-responses)."""
        if self.providers.openrouter.api_key:
            return self.providers.openrouter.api_type
        if self.providers.deepseek.api_key:
            return self.providers.deepseek.api_type
        if self.providers.anthropic.api_key:
            return self.providers.anthropic.api_type
        if self.providers.openai.api_key:
            return self.providers.openai.api_type
        if self.providers.gemini.api_key:
            return self.providers.gemini.api_type
        if self.providers.zhipu.api_key:
            return self.providers.zhipu.api_type
        if self.providers.groq.api_key:
            return self.providers.groq.api_type
        if self.providers.vllm.api_key or self.providers.vllm.api_base:
            return self.providers.vllm.api_type
        return None

    def get_api_headers(self) -> dict[str, str] | None:
        """Get extra headers for the active provider."""
        if self.providers.openrouter.api_key:
            return self.providers.openrouter.headers
        if self.providers.deepseek.api_key:
            return self.providers.deepseek.headers
        if self.providers.anthropic.api_key:
            return self.providers.anthropic.headers
        if self.providers.openai.api_key:
            return self.providers.openai.headers
        if self.providers.gemini.api_key:
            return self.providers.gemini.headers
        if self.providers.zhipu.api_key:
            return self.providers.zhipu.headers
        if self.providers.groq.api_key:
            return self.providers.groq.headers
        if self.providers.vllm.api_key or self.providers.vllm.api_base:
            return self.providers.vllm.headers
        return None

    def get_api_proxy(self) -> str | None:
        """Get proxy for the active provider."""
        if self.providers.openrouter.api_key:
            return self.providers.openrouter.proxy
        if self.providers.deepseek.api_key:
            return self.providers.deepseek.proxy
        if self.providers.anthropic.api_key:
            return self.providers.anthropic.proxy
        if self.providers.openai.api_key:
            return self.providers.openai.proxy
        if self.providers.gemini.api_key:
            return self.providers.gemini.proxy
        if self.providers.zhipu.api_key:
            return self.providers.zhipu.proxy
        if self.providers.groq.api_key:
            return self.providers.groq.proxy
        if self.providers.vllm.api_key or self.providers.vllm.api_base:
            return self.providers.vllm.proxy
        return None

    def get_drop_params(self) -> bool:
        """Check if optional params should be dropped for the active provider."""
        if self.providers.openrouter.api_key:
            return self.providers.openrouter.drop_params
        if self.providers.deepseek.api_key:
            return self.providers.deepseek.drop_params
        if self.providers.anthropic.api_key:
            return self.providers.anthropic.drop_params
        if self.providers.openai.api_key:
            return self.providers.openai.drop_params
        if self.providers.gemini.api_key:
            return self.providers.gemini.drop_params
        if self.providers.zhipu.api_key:
            return self.providers.zhipu.drop_params
        if self.providers.groq.api_key:
            return self.providers.groq.drop_params
        if self.providers.vllm.api_key or self.providers.vllm.api_base:
            return self.providers.vllm.drop_params
        return False
    
    class Config:
        env_prefix = "NANOBOT_"
        env_nested_delimiter = "__"
